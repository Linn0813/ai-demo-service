# encoding: utf-8
"""
LLMæ¨¡å‹è°ƒç”¨æœåŠ¡ï¼ˆå…±äº«ï¼‰
"""
from typing import Optional

import requests

from shared.config import LLM_CONFIG
from shared.logger import log


class LLMService:
    """LLMæ¨¡å‹è°ƒç”¨æœåŠ¡ - æµ‹è¯•ç”¨ä¾‹ç”Ÿæˆå’ŒçŸ¥è¯†åº“é—®ç­”å…±ç”¨"""

    def __init__(self, base_url: Optional[str] = None, model: Optional[str] = None,
                 temperature: Optional[float] = None, max_tokens: Optional[int] = None,
                 api_key: Optional[str] = None, provider: Optional[str] = None,
                 azure_deployment: Optional[str] = None, azure_api_version: Optional[str] = None):
        self.provider = provider or LLM_CONFIG.get("provider", "ollama")
        self.base_url = base_url or LLM_CONFIG["llm_base_url"]
        self.model = model or LLM_CONFIG["default_model"]
        self.temperature = temperature or LLM_CONFIG["temperature"]
        self.max_tokens = max_tokens or LLM_CONFIG["max_tokens"]
        self.timeout = LLM_CONFIG["timeout"]
        self.api_key = api_key or LLM_CONFIG.get("api_key", "")
        self.azure_deployment = azure_deployment or LLM_CONFIG.get("azure_deployment", "")
        self.azure_api_version = azure_api_version or LLM_CONFIG.get("azure_api_version", "2024-12-01-preview")

    def generate(self, prompt: str, max_retries: int = 2) -> str:
        """
        è°ƒç”¨LLMç”Ÿæˆå†…å®¹ï¼ˆå¸¦é‡è¯•æœºåˆ¶ï¼‰

        Args:
            prompt: è¾“å…¥çš„æç¤ºè¯
            max_retries: æœ€å¤§é‡è¯•æ¬¡æ•°

        Returns:
            LLMç”Ÿæˆçš„æ–‡æœ¬å†…å®¹

        Raises:
            ConnectionError: æ— æ³•è¿æ¥åˆ°LLMæœåŠ¡
            TimeoutError: è¯·æ±‚è¶…æ—¶
            RuntimeError: LLMæœåŠ¡è¯·æ±‚å¤±è´¥
        """
        last_error: Exception = ConnectionError("æœªçŸ¥é”™è¯¯")
        for attempt in range(max_retries + 1):
            try:
                # æ£€æŸ¥æœåŠ¡æ˜¯å¦å¯ç”¨ï¼ˆä»…å¯¹ Ollama è¿›è¡Œæ£€æŸ¥ï¼‰
                if self.provider == "ollama" and not self._check_service_available():
                    raise ConnectionError(f"æ— æ³•è¿æ¥åˆ°LLMæœåŠ¡: {self.base_url}")

                # æ ¹æ® provider ç±»å‹æ„å»ºä¸åŒçš„è¯·æ±‚
                if self.provider == "openai":
                    url, payload, headers = self._build_openai_request(prompt)
                else:  # ollama
                    url, payload, headers = self._build_ollama_request(prompt)

                log.debug(f"æ­£åœ¨è°ƒç”¨æ¨¡å‹: {self.model} (provider: {self.provider})...")
                
                # è°ƒè¯•æ—¥å¿—ï¼šè®°å½•è¯·æ±‚ä¿¡æ¯ï¼ˆä¸è®°å½•å®Œæ•´çš„ API keyï¼‰
                if self.provider == "openai":
                    log.info(f"ğŸ”µ Azure OpenAI API è°ƒç”¨:")
                    log.info(f"  URL: {url}")
                    log.info(f"  Model: {self.model}")
                    log.info(f"  Deployment: {self.azure_deployment or self.model}")
                    log.info(f"  Headers: {list(headers.keys())}")
                    log.info(f"  API Key å‰10å­—ç¬¦: {self.api_key[:10] + '...' if self.api_key else 'None'}")
                    log.info(f"  Payload keys: {list(payload.keys())}")
                    log.info(f"  Prompt length: {len(prompt)} å­—ç¬¦")
                
                response = requests.post(url, json=payload, headers=headers, timeout=self.timeout)
                response.raise_for_status()

                result = response.json()
                
                # æ ¹æ® provider ç±»å‹è§£æå“åº”
                if self.provider == "openai":
                    return self._parse_openai_response(result)
                else:  # ollama
                    return result.get("response", "")

            except requests.exceptions.ConnectionError as e:
                error_detail = str(e)
                last_error = ConnectionError(
                    f"æ— æ³•è¿æ¥åˆ°LLMæœåŠ¡ {self.base_url}ï¼Œè¯·ç¡®ä¿æœåŠ¡æ­£åœ¨è¿è¡Œã€‚"
                    f"é”™è¯¯è¯¦æƒ…: {error_detail}"
                )
                if attempt < max_retries:
                    log.warning(f"è¿æ¥å¤±è´¥ï¼ˆå°è¯• {attempt + 1}/{max_retries + 1}ï¼‰: {error_detail}")
                    continue
                raise last_error
            except requests.exceptions.Timeout as e:
                error_detail = str(e)
                last_error = TimeoutError(
                    f"è¯·æ±‚è¶…æ—¶ï¼ˆ{self.timeout}ç§’ï¼‰ï¼Œæ¨¡å‹: {self.model}ã€‚"
                    f"å¯èƒ½æ˜¯æ–‡æ¡£è¿‡é•¿æˆ–æ¨¡å‹å“åº”è¾ƒæ…¢ï¼Œè¯·å°è¯•å‡å°‘æ–‡æ¡£é•¿åº¦æˆ–å¢åŠ è¶…æ—¶æ—¶é—´ã€‚"
                    f"é”™è¯¯è¯¦æƒ…: {error_detail}"
                )
                if attempt < max_retries:
                    log.warning(f"è¯·æ±‚è¶…æ—¶ï¼ˆå°è¯• {attempt + 1}/{max_retries + 1}ï¼‰: {error_detail}")
                    continue
                raise last_error
            except requests.exceptions.HTTPError as e:
                error_detail = str(e)
                status_code = getattr(e.response, 'status_code', None) if hasattr(e, 'response') else None
                
                # å¦‚æœæ˜¯ 401 é”™è¯¯ï¼Œæä¾›æ›´è¯¦ç»†çš„é”™è¯¯ä¿¡æ¯
                if status_code == 401:
                    response_text = ""
                    response_json = None
                    if hasattr(e, 'response') and e.response is not None:
                        try:
                            response_text = e.response.text[:500]  # å–å‰500å­—ç¬¦
                            try:
                                response_json = e.response.json()
                            except:
                                pass
                        except:
                            pass
                    
                    # è®°å½•è¯¦ç»†çš„é”™è¯¯ä¿¡æ¯
                    log.error(f"âŒ Azure OpenAI è®¤è¯å¤±è´¥ (401):")
                    log.error(f"  URL: {url}")
                    log.error(f"  Deployment: {self.azure_deployment or self.model}")
                    log.error(f"  API Key å‰20å­—ç¬¦: {self.api_key[:20] + '...' if self.api_key else 'None'}")
                    log.error(f"  å“åº”çŠ¶æ€ç : {status_code}")
                    log.error(f"  å“åº”å†…å®¹: {response_text}")
                    if response_json:
                        log.error(f"  å“åº”JSON: {response_json}")
                    
                    last_error = RuntimeError(
                        f"LLMæœåŠ¡è®¤è¯å¤±è´¥ï¼ˆ401 Unauthorizedï¼‰ï¼Œæ¨¡å‹: {self.model}ï¼Œéƒ¨ç½²: {self.azure_deployment or self.model}ã€‚"
                        f"è¯·æ£€æŸ¥ï¼š1) API key æ˜¯å¦æ­£ç¡®ï¼›2) éƒ¨ç½²åç§°æ˜¯å¦æ­£ç¡®ï¼›3) API key æ˜¯å¦æœ‰è®¿é—®è¯¥éƒ¨ç½²çš„æƒé™ã€‚"
                        f"å“åº”è¯¦æƒ…: {response_text}"
                    )
                else:
                    last_error = RuntimeError(
                        f"LLMæœåŠ¡HTTPé”™è¯¯ï¼ˆçŠ¶æ€ç : {status_code}ï¼‰ï¼Œæ¨¡å‹: {self.model}ã€‚"
                        f"é”™è¯¯è¯¦æƒ…: {error_detail}"
                    )
                
                if attempt < max_retries:
                    log.warning(f"HTTPé”™è¯¯ï¼ˆå°è¯• {attempt + 1}/{max_retries + 1}ï¼‰: {error_detail}")
                    continue
                raise last_error
            except requests.exceptions.RequestException as e:
                error_detail = str(e)
                last_error = RuntimeError(
                    f"LLMæœåŠ¡è¯·æ±‚å¤±è´¥ï¼Œæ¨¡å‹: {self.model}ï¼ŒURL: {self.base_url}ã€‚"
                    f"é”™è¯¯è¯¦æƒ…: {error_detail}"
                )
                if attempt < max_retries:
                    log.warning(f"è¯·æ±‚å¤±è´¥ï¼ˆå°è¯• {attempt + 1}/{max_retries + 1}ï¼‰: {error_detail}")
                    continue
                raise last_error

        # ç†è®ºä¸Šä¸åº”è¯¥åˆ°è¾¾è¿™é‡Œï¼ˆæ‰€æœ‰é‡è¯•éƒ½ä¼šæŠ›å‡ºå¼‚å¸¸æˆ–è¿”å›ï¼‰
        # ä½†ä¸ºäº†æ»¡è¶³ç±»å‹æ£€æŸ¥ï¼Œæ·»åŠ æ–­è¨€
        assert False, "æ‰€æœ‰é‡è¯•éƒ½å¤±è´¥ï¼Œåº”è¯¥å·²ç»æŠ›å‡ºå¼‚å¸¸"
        raise last_error  # type: ignore

    def _build_ollama_request(self, prompt: str):
        """æ„å»º Ollama API è¯·æ±‚"""
        url = f"{self.base_url}/api/generate"
        payload = {
            "model": self.model,
            "prompt": prompt,
            "stream": False,
            "options": {
                "temperature": self.temperature,
                "num_predict": self.max_tokens
            }
        }
        headers = {}
        return url, payload, headers

    def _build_openai_request(self, prompt: str):
        """æ„å»º OpenAI å…¼å®¹ API è¯·æ±‚"""
        # æ£€æµ‹æ˜¯å¦æ˜¯ Azure OpenAI Service
        is_azure = "cognitiveservices.azure.com" in self.base_url or "openai.azure.com" in self.base_url
        
        if is_azure:
            # Azure OpenAI Service ç«¯ç‚¹æ ¼å¼ï¼š
            # æ ‡å‡†æ ¼å¼ï¼šhttps://{resource}.openai.azure.com/openai/deployments/{deployment}/chat/completions?api-version={version}
            # æ—§æ ¼å¼ï¼šhttps://{resource}.cognitiveservices.azure.com/openai/deployments/{deployment}/chat/completions?api-version={version}
            # æ–°æ ¼å¼ï¼ˆv1 APIï¼‰ï¼šhttps://{resource}.openai.azure.com/openai/v1/chat/completions?api-version={version}
            
            # å¦‚æœ base_url å·²ç»åŒ…å«å®Œæ•´è·¯å¾„ï¼Œç›´æ¥ä½¿ç”¨
            if "/openai/deployments/" in self.base_url or "/openai/v1/" in self.base_url:
                url = self.base_url
                if "api-version" not in url:
                    url = f"{url}?api-version={self.azure_api_version}"
            else:
                # æ„å»º Azure OpenAI Service ç«¯ç‚¹
                # ä½¿ç”¨é…ç½®çš„ deployment nameï¼Œå¦‚æœæ²¡æœ‰åˆ™ä½¿ç”¨æ¨¡å‹åç§°
                deployment = self.azure_deployment or self.model
                base = self.base_url.rstrip('/')
                
                # ä½¿ç”¨åŸå§‹çš„ base_urlï¼ˆä¸è¿›è¡Œè½¬æ¢ï¼‰
                # æ ¹æ®å®é™…æµ‹è¯•ï¼Œcognitiveservices.azure.com æ ¼å¼æ˜¯æ­£ç¡®çš„
                # ä½¿ç”¨ä¼ ç»Ÿçš„ deployments ç«¯ç‚¹æ ¼å¼
                url = f"{base}/openai/deployments/{deployment}/chat/completions?api-version={self.azure_api_version}"
        else:
            # æ ‡å‡† OpenAI å…¼å®¹ API é€šå¸¸ä½¿ç”¨ /v1/chat/completions ç«¯ç‚¹
            # å¦‚æœ base_url å·²ç»åŒ…å« /v1ï¼Œåˆ™ç›´æ¥ä½¿ç”¨ï¼Œå¦åˆ™æ·»åŠ  /v1
            if self.base_url.endswith("/v1"):
                url = f"{self.base_url}/chat/completions"
            elif "/v1" in self.base_url:
                url = f"{self.base_url}/chat/completions"
            else:
                url = f"{self.base_url.rstrip('/')}/v1/chat/completions"
        
        # Azure OpenAI Service éœ€è¦åœ¨ model å­—æ®µä¸­ä½¿ç”¨ deployment åç§°
        if is_azure:
            model_for_request = self.azure_deployment or self.model
        else:
            model_for_request = self.model
        
        payload = {
            "model": model_for_request,
            "messages": [
                {
                    "role": "user",
                    "content": prompt
                }
            ],
        }
        
        # gpt-5.2-chat æ¨¡å‹çš„ç‰¹æ®Šå¤„ç†
        is_gpt52 = is_azure and ("gpt-5.2" in model_for_request.lower() or "gpt-5" in model_for_request.lower())
        
        if is_gpt52:
            # gpt-5.2-chat ä½¿ç”¨ max_completion_tokens è€Œä¸æ˜¯ max_tokens
            payload["max_completion_tokens"] = self.max_tokens
            # gpt-5.2-chat åªæ”¯æŒ temperature=1ï¼ˆé»˜è®¤å€¼ï¼‰ï¼Œä¸æ”¯æŒå…¶ä»–å€¼
            # ä¸è®¾ç½® temperatureï¼Œä½¿ç”¨é»˜è®¤å€¼
        else:
            payload["temperature"] = self.temperature
            payload["max_tokens"] = self.max_tokens
        
        headers = {
            "Content-Type": "application/json"
        }
        
        # æ·»åŠ  API key è®¤è¯
        if self.api_key:
            if is_azure:
                # Azure OpenAI Service ä½¿ç”¨ api-key å¤´ï¼ˆAzure ç‰¹æœ‰æ ¼å¼ï¼‰
                headers["api-key"] = self.api_key
            else:
                # æ ‡å‡† OpenAI API ä½¿ç”¨ Authorization Bearer å¤´
                headers["Authorization"] = f"Bearer {self.api_key}"
        
        return url, payload, headers

    def _parse_openai_response(self, result: dict) -> str:
        """è§£æ OpenAI å…¼å®¹ API å“åº”"""
        # OpenAI æ ¼å¼: {"choices": [{"message": {"content": "..."}}]}
        if "choices" in result and len(result["choices"]) > 0:
            choice = result["choices"][0]
            if "message" in choice and "content" in choice["message"]:
                return choice["message"]["content"]
            elif "text" in choice:
                return choice["text"]
        
        # å…¼å®¹å…¶ä»–å¯èƒ½çš„å“åº”æ ¼å¼
        if "content" in result:
            return result["content"]
        if "text" in result:
            return result["text"]
        if "response" in result:
            return result["response"]
        
        # å¦‚æœæ— æ³•è§£æï¼Œè¿”å›æ•´ä¸ªå“åº”çš„å­—ç¬¦ä¸²è¡¨ç¤º
        log.warning(f"æ— æ³•è§£æ OpenAI å“åº”æ ¼å¼: {result}")
        return str(result)

    def _check_service_available(self) -> bool:
        """æ£€æŸ¥LLMæœåŠ¡æ˜¯å¦å¯ç”¨ï¼ˆä»…ç”¨äº Ollamaï¼‰"""
        if self.provider != "ollama":
            return True  # OpenAI å…¼å®¹ API ä¸éœ€è¦é¢„å…ˆæ£€æŸ¥
        
        try:
            response = requests.get(f"{self.base_url}/api/tags", timeout=5)
            return response.status_code == 200
        except:
            return False

